# Construction Accident Prevention Agent

건설공사 사고 상황 데이터를 기반으로 사고 원인 분석 및 재발 방지 대책을 생성하는 AI 시스템

---

## 🔍 **프로젝트 소개**

**Construction Accident Prevention Agent**는 건설공사 사고 상황 데이터를 분석하여, 사고 원인과 재발 방지 대책을 자동 생성하는 AI 시스템입니다.
본 프로젝트는 한솔데코 시즌3 AI 경진대회를 기반으로 진행되었으며, 주어진 사고 상황에 대해 짧고 간결한 대응 문구를 생성하는 것을 목표로 합니다.

---

## 👤 **프로젝트 정보**

* **프로젝트 유형:** 팀 프로젝트(5인)
* **프로젝트 기간:** 2025.02.17 \~ 2025.03.24

---

## 🧑‍💻 **나의 역할**

* 각자 A to Z를 진행하되 방법을 공유

* 사고 보고서 데이터 전처리 및 메타데이터 분류

* 사고 유형에 따른 동적 필터링 기반 RAG 검색 시스템 구축

* Ollama로 불러온 Gemma3:27b 모델을 활용한 대응책 생성

* **FAISS를 사용한 벡터 스토어 구축(CSV 파일과 pdf 파일을 각각 다른 벡터 스토어로 분리하여 2가지 벡터 스토어를 만드는 경우와 pdf 파일만을 임베딩하여 1가지 벡터 스토어만 사용하는 경우 나눠서 진행)**

* **프롬프트 엔지니어링**

* **다양한 Retriever 방식을 바꿔가며 RAG 진행**

  * **단일 검색기 (Single Retriever)**: 유사도 기반 단일 검색 (FAISS, Chroma)
  * **혼합 검색기 (Hybrid Retriever)**: PDF와 CSV를 결합하여 가중 합산 검색 (PDF: 80%, CSV: 20%)
  * **다단계 검색기 (Map-Reduce Retriever)**: 문서별 요약을 생성하고 최종 요약을 결합하여 최적 대책 도출
  * **복합 질문 처리 (Map-Reduce with Ensemble)**: 복합 질문에 대해 단계별 요약과 최종 종합 대책을 도출

* **Rerank 기반 검색기 (Reranker Retriever)**:

  * 모델명: **Dongjin-kr/ko-reranker**
  * `ContextualCompressionRetriever`와 `CrossEncoderReranker`를 활용하여 문서 순위 재조정
  * 상위 문서 필터링 후, 정확도가 높은 순으로 재정렬하여 최적의 문서를 반환

* 최종 대응 결과 CSV 파일로 저장

---

## 📈 **프로젝트 주요 기능**

* **데이터 전처리:** 사고 상황 데이터 정제 및 메타데이터 분류
* **RAG 검색 시스템:** 유사 사고 사례 검색 및 문맥 생성
* **LLM 답변 생성:** LLM을 이용한 대응 문구 생성
* **GPU 가속 처리:** RAG 배치 처리 및 임베딩 배치 최적화
* **결과 제출 파일 생성:** 대응 문구 및 임베딩 결과를 CSV로 저장

---

## 🛠️ **프로젝트 기술 스택**

Language : 🐍 Python
Library : 🔗 LangChain | 🧠 SentenceTransformer | 🛠️ FAISS
Tool : 🐙 GitHub

---

## 🖥️ **시스템 아키텍처 요약**

* **PDF 텍스트 파일 로드 및 메타데이터 자동 분류**

* **ko-sbert-sts 기반 텍스트 임베딩 및 FAISS 벡터스토어 구축**

* **LangChain을 통한 RAG 검색 및 유사 문맥 추출**

* **Ollama로 불러온 Gemma3:27b 모델을 사용하여 간결한 대응 문구 생성**

* **최종 결과를 CSV 파일로 저장**

---

## 📊 **프로젝트 결과 및 회고**

### ✅ **프로젝트 결과**

* 주어진 사고 상황에 대해 대응책을 생성하는 시스템을 성공적으로 구축했으나, 최종 대회 평가에서는 팀 최고 점수인 **자카르 유사도 약 0.49**의 성능을 기록하여 **본선 진출에 실패**했습니다.

### ✅ **회고**

* **데이터 전처리** 과정에서, 특히 **결측치 처리** 및 **유효 데이터 선별** 부분이 미흡하여 모델 입력 품질에 영향을 주었음을 인지했습니다.
* **프롬프트 엔지니어링**을 하다보니 느낀 것이 LLM에게 지켜야 할 지침을 처음에는 계속 프롬프트의 앞 부분에 먼저 작성해주었는데 프롬프트가 길어지다보니 자꾸 지침을 따르지 않는 경우가 있어 지침을 프롬프트의 가장 마지막 부분에 작성했더니 지침을 따르는 걸 확인했다. 그래서 LLM도 사람을 모방하여 만들어서 그런지 프롬프트가 길어지면 앞의 말을 잊어버리는 것 같다고 느꼈습니다. 
* **LLM(언어 모델)을 직접 파인튜닝**할 수 있었다면, 더욱 일관성 있고 우수한 대응 문구를 생성할 수 있었을 것으로 판단됩니다.
* 또한, **임베딩 품질 개선**이나 **벡터 검색 최적화**를 통해 대회 점수를 높이려고 시도했는데 이 부분보다는 데이터 전처리나 문서 파싱에 더 많은 공을 들였어야 했다고 판단됩니다.

---

### 🔄 **향후 개선 방향**

* 사고 상황별 특성에 맞는 **도메인 특화 프롬프트** 설계
* **사전 학습된 LLM 파인튜닝**을 통한 생성 품질 향상
* **전처리 강화** 및 **텍스트 데이터 품질 향상**을 통한 시스템 전반적 성능 개선
